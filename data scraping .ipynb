{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the website\n",
    "driver.get(\"\")  #provide the link that you want to scrape\n",
    "driver.maximize_window()            #maximize the window button\n",
    "time.sleep(5)  # Wait for 5min the page to load\n",
    "\n",
    "#some website ask the signup \n",
    "# Function to close the signup popup if it appears\n",
    "def close_signup_popup():\n",
    "    try:\n",
    "        close_button = driver.find_element(By.CLASS_NAME, \"icon-cross\")\n",
    "        driver.execute_script(\"arguments[0].click();\", close_button)\n",
    "        time.sleep(2)  # Wait for the popup to close\n",
    "        print(\"Signup popup closed.\")  #ensure it has closed\n",
    "    except NoSuchElementException:\n",
    "        # If the popup is not found, we just continue\n",
    "        pass\n",
    "\n",
    "# Locate the route element by its class name 'route'\n",
    "def get_links_and_text():\n",
    "    roots = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    root_names = [i.text for i in roots]   #get the all route name through the loop\n",
    "    links = [element.get_attribute('href') for element in roots]   #get the links based on the route name\n",
    "    return root_names, links\n",
    "\n",
    "#many website have more than one page \n",
    "def go_to_next_page():\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    try:\n",
    "        #select the xpath in active page\n",
    "        active_page_element = driver.find_element(By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\")  \n",
    "        active_page_number = active_page_element.text\n",
    "        next_page_number = str(int(active_page_number) + 1)  #move to the next page by add 1 with current page value \n",
    "        \n",
    "        next_page_button = wait.until(EC.element_to_be_clickable((By.XPATH, f\"//div[@class='DC_117_paginationTable']//div[text()='{next_page_number}']\")))\n",
    "        next_page_button.click()  #you can move to the next page by clcicking specificic element\n",
    "        time.sleep(5)  # Wait for the next page to load\n",
    "    except Exception as e:\n",
    "        print(f\"Error while clicking next page: {e}\")\n",
    "\n",
    "# Retrieve data from all pages\n",
    "all_root_names = []   #create the empty list \n",
    "all_links = []\n",
    "\n",
    "for i in range():  # Assuming there are multiple pages\n",
    "    root_names, links = get_links_and_text()\n",
    "    all_root_names.extend(root_names)  #inser the all data my extend method instead of append\n",
    "    all_links.extend(links)\n",
    "    if i < :  # Adjust based on the number of pages.because ,the loop starts from 0,1,2...\n",
    "        go_to_next_page()\n",
    "\n",
    "# Navigate to each route and extract bus data\n",
    "bus_data = []   #create a mpty list to store the data\n",
    "\n",
    "for route_name, link in zip(all_root_names, all_links):  #the loop iterate the link based on route name, link\n",
    "    driver.get(link)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "    # Find all \"View Buses\" buttons\n",
    "    #the view bus option contain some goverment bus details\n",
    "    view_buses_buttons = driver.find_elements(By.CLASS_NAME, \"button\")\n",
    "\n",
    "    for button in view_buses_buttons:\n",
    "        try:\n",
    "            #we can acess those data by clicking the \"view bus\" option\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Close the signup popup if it appears\n",
    "            close_signup_popup()\n",
    "            \n",
    "            #some websites have scroll bar , to extend the page range for display more data\n",
    "            #we can acess those data by scrolling the page\n",
    "            # Scroll down to load more buses\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\") #javascript commends  1st time\n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(5)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")  #javascript commends  2st time\n",
    "                if new_height == last_height:  #check the conditions are same \n",
    "                    break    #if it is true break the loop\n",
    "                last_height = new_height #assign the values to each other\n",
    "\n",
    "            # Extract bus details\n",
    "            bus_elements = driver.find_elements(By.CLASS_NAME, 'row-sec')   #assign that division element\n",
    "\n",
    "            for element in bus_elements:\n",
    "                try:\n",
    "                    bus_name = element.find_element(By.CLASS_NAME, 'travels').text.strip()  #busname element\n",
    "                    bus_type = element.find_element(By.CLASS_NAME, 'bus-type').text.strip()  #bustype element\n",
    "                    departing_time = element.find_element(By.CLASS_NAME, 'dp-time').text.strip()  #starting time element\n",
    "                    duration = element.find_element(By.CLASS_NAME, 'dur').text.strip()         #duration elelemnt \n",
    "                    reaching_time = element.find_element(By.CLASS_NAME, 'bp-time').text.strip()  #reaching time element\n",
    "                    star_rating = element.find_element(By.XPATH, './/div[@class=\"rating-sec lh-24\"]//span').text.strip()  #star rating element by xpath\n",
    "                    try:\n",
    "                        price_element = element.find_element(By.CSS_SELECTOR, 'span.f-19.f-bold')  #price element by css selector\n",
    "                        price = price_element.text.strip()\n",
    "                    except NoSuchElementException:\n",
    "                        price = \"Price not available\"\n",
    "\n",
    "                    seats_available = element.find_element(By.CLASS_NAME, 'seat-left').text.strip().split()[0]  #seats element by selecting first index value\n",
    "\n",
    "                    bus_data.append({    #assign the all data in dictionary structure by append method \n",
    "                        \"Route Name\": route_name,\n",
    "                        \"Route Link\": link,\n",
    "                        \"Bus Name\": bus_name,\n",
    "                        \"Bus Type\": bus_type,\n",
    "                        \"Departing Time\": departing_time,\n",
    "                        \"Duration\": duration,\n",
    "                        \"Reaching Time\": reaching_time,\n",
    "                        \"Star Rating\": star_rating,\n",
    "                        \"Price\": price,\n",
    "                        \"Seats Available\": int(seats_available)\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting bus data: {e}\")  # Print the error message to help with debugging and continue execution\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error clicking 'View Buses' button: {e}\")  \n",
    "\n",
    "# Save the extracted bus data to a CSV file\n",
    "csv_file_path = \"punjab.csv\"  #set file name and extension\n",
    "# Open the CSV file in write mode ('w') with specified newline and encoding settings\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    # Create a CSV DictWriter object, specifying the fieldnames based on the keys of the first dictionary in bus_data\n",
    "    writer = csv.DictWriter(file, fieldnames=bus_data[0].keys())\n",
    "    writer.writeheader()   #take the first row as headr\n",
    "    # Write all the rows of bus data to the CSV file\n",
    "    writer.writerows(bus_data)\n",
    "\n",
    "#ensure the file has been saved\n",
    "print(f\"Data has been saved to {csv_file_path}\")\n",
    "\n",
    "# Close the browser\n",
    "time.sleep(5)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the file with specified encoding\n",
    "pj = pd.read_csv(r'D:\\0.Projects -Guvi\\punjab.csv', encoding='utf-8')\n",
    "\n",
    "# Remove duplicate rows\n",
    "pj_cleaned = pj.drop_duplicates()\n",
    "\n",
    "# Save the cleaned data back to the same file, overwriting it\n",
    "pj_cleaned.to_csv(r'D:\\0.Projects -Guvi\\punjab.csv', index=False, encoding='utf-8')\n",
    "\n",
    "#ensure the duplicates are removed and the file has been updated\n",
    "print(\"Duplicates removed and data saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
